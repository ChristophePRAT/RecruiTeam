{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 139, "column": 0}, "map": {"version":3,"sources":["file:///Users/christopheprat/Code/Side-projs/Hackathons/code-interview/src/app/voicec/page.tsx"],"sourcesContent":["\"use client\";\n\nimport { useEffect, useState } from \"react\";\nimport {\n    RealtimeAgent,\n    RealtimeSession,\n    TransportLayerAudio,\n} from \"@openai/agents/realtime\";\n\nexport default function Home() {\n    const [status, setStatus] = useState(\"idle\");\n\n    useEffect(() => {\n        async function setup() {\n            setStatus(\"fetching key...\");\n            const res = await fetch(\"/api/session\", { method: \"POST\" });\n            const { value: ephemeralKey } = await res.json();\n\n            setStatus(\"creating agent...\");\n            const agent = new RealtimeAgent({\n                name: \"Assistant\",\n                instructions: \"You are a helpful voice assistant.\",\n            });\n\n            const session = new RealtimeSession(agent, {\n                model: \"gpt-realtime\",\n            });\n\n            setStatus(\"connecting...\");\n            await session.connect({ apiKey: ephemeralKey });\n\n            setStatus(\"connected! Start speaking.\");\n            const newlyRecordedAudio = new ArrayBuffer(0);\n\n            // send new audio to the agent\n            session.sendAudio(newlyRecordedAudio);\n\n            session.on(\"audio\", (event: TransportLayerAudio) => {\n                console.log(\"POIHJDSFPOISHJDFPOISDHJ\");\n                const audioData = event.data;\n                const audioContext = new AudioContext();\n                const audioBuffer = audioContext.createBuffer(\n                    1,\n                    audioData.length,\n                    audioContext.sampleRate,\n                );\n                const channelData = audioBuffer.getChannelData(0);\n                channelData.set(audioData);\n\n                const source = audioContext.createBufferSource();\n                source.buffer = audioBuffer;\n                source.connect(audioContext.destination);\n                source.start(); // play your audio\n            });\n        }\n\n        setup();\n    }, []);\n\n    return (\n        <main className=\"p-10\">\n            <h1 className=\"text-2xl font-bold\">üéôÔ∏è My Voice Agent</h1>\n            <p>Status: {status}</p>\n        </main>\n    );\n}\n"],"names":[],"mappings":";;;;;AAEA;AACA;AAAA;AAHA;;;;AASe,SAAS;IACpB,MAAM,CAAC,QAAQ,UAAU,GAAG,IAAA,wXAAQ,EAAC;IAErC,IAAA,yXAAS,EAAC;QACN,eAAe;YACX,UAAU;YACV,MAAM,MAAM,MAAM,MAAM,gBAAgB;gBAAE,QAAQ;YAAO;YACzD,MAAM,EAAE,OAAO,YAAY,EAAE,GAAG,MAAM,IAAI,IAAI;YAE9C,UAAU;YACV,MAAM,QAAQ,IAAI,iRAAa,CAAC;gBAC5B,MAAM;gBACN,cAAc;YAClB;YAEA,MAAM,UAAU,IAAI,mRAAe,CAAC,OAAO;gBACvC,OAAO;YACX;YAEA,UAAU;YACV,MAAM,QAAQ,OAAO,CAAC;gBAAE,QAAQ;YAAa;YAE7C,UAAU;YACV,MAAM,qBAAqB,IAAI,YAAY;YAE3C,8BAA8B;YAC9B,QAAQ,SAAS,CAAC;YAElB,QAAQ,EAAE,CAAC,SAAS,CAAC;gBACjB,QAAQ,GAAG,CAAC;gBACZ,MAAM,YAAY,MAAM,IAAI;gBAC5B,MAAM,eAAe,IAAI;gBACzB,MAAM,cAAc,aAAa,YAAY,CACzC,GACA,UAAU,MAAM,EAChB,aAAa,UAAU;gBAE3B,MAAM,cAAc,YAAY,cAAc,CAAC;gBAC/C,YAAY,GAAG,CAAC;gBAEhB,MAAM,SAAS,aAAa,kBAAkB;gBAC9C,OAAO,MAAM,GAAG;gBAChB,OAAO,OAAO,CAAC,aAAa,WAAW;gBACvC,OAAO,KAAK,IAAI,kBAAkB;YACtC;QACJ;QAEA;IACJ,GAAG,EAAE;IAEL,qBACI,qZAAC;QAAK,WAAU;;0BACZ,qZAAC;gBAAG,WAAU;0BAAqB;;;;;;0BACnC,qZAAC;;oBAAE;oBAAS;;;;;;;;;;;;;AAGxB","debugId":null}}]
}